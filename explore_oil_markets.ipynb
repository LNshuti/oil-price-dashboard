{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the text file\n",
    "data = pd.read_csv('data/raw/PET/PET.txt', sep='\\t', header=None, names=['json_str'])\n",
    "\n",
    "# Function to parse JSON strings\n",
    "def parse_json_str(json_str):\n",
    "    return json.loads(json_str)\n",
    "\n",
    "# Apply the function to parse the JSON strings\n",
    "parsed_data = data['json_str'].apply(parse_json_str)\n",
    "\n",
    "# Create a DataFrame from the parsed JSON data\n",
    "df = pd.json_normalize(parsed_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9482765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'data' column to separate rows for each date-value pair\n",
    "df = df.explode('data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select distinct series_id, name, units\n",
    "df_series = df[['series_id', 'name', 'units']].drop_duplicates()\n",
    "df_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a count of the number of records by units \n",
    "df_series['units'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include name containing 'Louisiana' and units in Dollars per Gallon\n",
    "df_louisiana = df[df['name'].str.contains('Louisiana Total') & df['units'].str.contains('Dollars per Gallon')]\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17028f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'data' is NaN or not a list\n",
    "df_louisiana = df_louisiana.dropna(subset=['data'])\n",
    "df_louisiana = df_louisiana[df_louisiana['data'].apply(lambda x: isinstance(x, list) and len(x) == 2)]\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba622fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'data' column into 'date' and 'value'\n",
    "df_louisiana[['date', 'value']] = pd.DataFrame(df_louisiana['data'].tolist(), index=df_louisiana.index)\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5718761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime, coercing errors to NaT\n",
    "df_louisiana['date'] = pd.to_datetime(df_louisiana['date'], format='%Y%m%d', errors='coerce')\n",
    "# Convert 'value' to a numeric type, coercing errors to NaN\n",
    "df_louisiana['value'] = pd.to_numeric(df_louisiana['value'], errors='coerce')\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_louisiana.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns and preprocess the data\n",
    "df_louisiana['Date'] = pd.to_datetime(df_louisiana['date'])\n",
    "df_louisiana['Price'] = df_louisiana['value']\n",
    "df_louisiana = df_louisiana[['Date', 'Price', 'unitsshort', 'name']].sort_values(by='Date').reset_index(drop=True)\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13752fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "def load_gas_price_data():\n",
    "    df = pd.read_csv('data\\processed\\louisiana_tot_gasoline_wholesale_monthly.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Convert 'date' to datetime, coercing errors\n",
    "    df = df[['date', 'value']].dropna()  # Keep only necessary columns and drop NA values\n",
    "    return df\n",
    "\n",
    "# Prepare data for long format and additional transformations\n",
    "def prepare_data(df):\n",
    "    df = df.sort_values('date')\n",
    "    df['log_price'] = np.log(df['value'])\n",
    "    df['price_change'] = df['log_price'].diff()\n",
    "    return df\n",
    "\n",
    "# Function to perform AutoARIMA forecasting\n",
    "def forecast_prices(df, cutoff_date):\n",
    "    # Filter the DataFrame based on the cutoff date\n",
    "    df_filtered = df[df['date'] < pd.to_datetime(cutoff_date)]\n",
    "    \n",
    "    # Convert prices to log prices to stabilize variance\n",
    "    df_filtered['log_price'] = np.log(df_filtered['value'])\n",
    "    \n",
    "    # Define the model\n",
    "    model = SARIMAX(df_filtered['log_price'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    \n",
    "    # Fit the model\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Generate future dates\n",
    "    future_dates = pd.date_range(df_filtered['date'].max() + MonthEnd(1), periods=13, freq='M')\n",
    "    \n",
    "    # Forecast future log prices\n",
    "    forecast_log_prices = results.forecast(steps=13)\n",
    "    \n",
    "    # Convert log prices back to regular prices\n",
    "    forecast_prices = np.exp(forecast_log_prices)\n",
    "    \n",
    "    # Create a DataFrame for the forecasted prices\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'date': future_dates,\n",
    "        'forecast_price': forecast_prices\n",
    "    })\n",
    "    \n",
    "    return forecast_df\n",
    "\n",
    "# Visualization function\n",
    "def plot_forecast(df, forecast_df):\n",
    "    base = alt.Chart(df).encode(\n",
    "        x='date:T',\n",
    "        y='value:Q'\n",
    "    ).properties(\n",
    "        width=700,\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    line = base.mark_line(color='blue', size=3)\n",
    "    points = base.mark_point(color='red')\n",
    "\n",
    "    forecast_chart = alt.Chart(forecast_df).mark_line(color='green').encode(\n",
    "        x='date:T',\n",
    "        y='forecast_price:Q'\n",
    "    )\n",
    "\n",
    "    return line + points + forecast_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1967d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_gas_price_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec131a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = prepare_data(df)\n",
    "df_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6332a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = forecast_prices(df, '2021-01-01')\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca84236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(df, forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'models/oil_price_forecast_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
