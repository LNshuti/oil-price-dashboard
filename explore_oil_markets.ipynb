{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "\n",
    "# Fix for MaxRowsError\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the text file\n",
    "data = pd.read_csv('data/raw/PET/PET.txt', sep='\\t', header=None, names=['json_str'])\n",
    "data['json_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816949fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_str(json_str):\n",
    "    \"\"\"\n",
    "    Parse a JSON string and return a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    json_str (str): A string in JSON format.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary parsed from the JSON string. If the input string is empty or invalid, an empty dictionary is returned.\n",
    "    \"\"\"\n",
    "    if not json_str:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "# Apply the function to parse the JSON strings\n",
    "parsed_data = data['json_str'].apply(parse_json_str)\n",
    "\n",
    "# Create a DataFrame from the parsed JSON data\n",
    "df = pd.json_normalize(parsed_data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9482765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'data' column to separate rows for each date-value pair\n",
    "df = df.explode('data')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select distinct series_id, name, units\n",
    "df_series = df[['series_id', 'name', 'units', 'unitsshort']].drop_duplicates()\n",
    "df_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c57b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on columns: 'series_id', 'units'\n",
    "df_series_nonas = df_series[(df_series['series_id'].notna()) & (df_series['units'].notna())]\n",
    "df_series_nonas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_all = df.groupby('name')['end'].agg(['min', 'max'])\n",
    "date_range_all_nonas = date_range_all[(date_range_all['min'].notna()) & (date_range_all['max'].notna())]\n",
    "date_range_all_nonas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a count of the number of records by units \n",
    "df_series['units'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include name containing 'Louisiana' and units in Dollars per Gallon\n",
    "df_louisiana = df[df['name'].str.contains('Louisiana Total') & df['units'].str.contains('Dollars per Gallon')]\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17028f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'data' is NaN or not a list\n",
    "df_louisiana = df_louisiana.dropna(subset=['data'])\n",
    "df_louisiana = df_louisiana[df_louisiana['data'].apply(lambda x: isinstance(x, list) and len(x) == 2)]\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba622fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'data' column into 'date' and 'value'\n",
    "df_louisiana[['date', 'value']] = pd.DataFrame(df_louisiana['data'].tolist(), index=df_louisiana.index)\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5718761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime, coercing errors to NaT\n",
    "df_louisiana['date'] = pd.to_datetime(df_louisiana['date'], format='%Y%m%d', errors='coerce')\n",
    "# Convert 'value' to a numeric type, coercing errors to NaN\n",
    "df_louisiana['value'] = pd.to_numeric(df_louisiana['value'], errors='coerce')\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_louisiana.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns and preprocess the data\n",
    "df_louisiana['Date'] = pd.to_datetime(df_louisiana['date'])\n",
    "df_louisiana['Price'] = df_louisiana['value']\n",
    "df_louisiana = df_louisiana[['Date', 'Price', 'unitsshort', 'series_id', 'name', 'last_updated']].sort_values(by='Date').reset_index(drop=True)\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_la = df_louisiana.groupby(['name', 'series_id'])['Date'].agg(['min', 'max'])\n",
    "date_range_la.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the table when both min and max are not equal to NaT \n",
    "date_range_la_nonas = date_range_la[(date_range_la['min'].notna()) & (date_range_la['max'].notna())]\n",
    "date_range_la_nonas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13752fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "def load_gas_price_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset from a raw text file containing JSON strings.\n",
    "    \n",
    "    Parameters:\n",
    "    - filepath: Path to the .txt file containing the raw data.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame with the data extracted from JSON strings, focusing on 'date' and 'value' columns.\n",
    "    \"\"\"\n",
    "    # Load the data from the text file\n",
    "    data = pd.read_csv(filepath, sep='\\t', header=None, names=['json_str'])\n",
    "    \n",
    "    # Function to parse JSON strings\n",
    "    def parse_json_str(json_str):\n",
    "        return json.loads(json_str)\n",
    "    \n",
    "    # Apply the function to parse the JSON strings\n",
    "    parsed_data = data['json_str'].apply(parse_json_str)\n",
    "    \n",
    "    # Create a DataFrame from the parsed JSON data\n",
    "    df = pd.json_normalize(parsed_data)\n",
    "\n",
    "    # Keep only necessary columns and drop NA values\n",
    "    #df = df[['date', 'value']].dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare data for long format and additional transformations\n",
    "def prepare_data(df, series_id=\"PET.EMA_EPM0_PBS_SLA_DPG.M\"):\n",
    "    \"\"\"\n",
    "    Prepare the dataset for analysis by performing several transformations.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame to be transformed.\n",
    "    - series_id: The series ID to filter the DataFrame by. Default is \"PET.EMA_EPM0_PBS_SLA_DPG.M\".\n",
    "    \n",
    "    Returns:\n",
    "    - Transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Filter based on series_id and non-NA 'units' column\n",
    "    df = df[df['series_id'] == series_id]\n",
    "\n",
    "    # Only select relevant columns used in downstream analysis\n",
    "    df = df[['name', 'units', 'unitsshort', 'data', 'end']]\n",
    "    \n",
    "\n",
    "    # Explode the 'data' column to separate rows for each date-value pair\n",
    "    df = df.explode('data')\n",
    "    \n",
    "    # Drop rows where 'data' is NaN or not a list\n",
    "    df = df.dropna(subset=['data'])\n",
    "    df = df[df['data'].apply(lambda x: isinstance(x, list) and len(x) == 2)]\n",
    "    \n",
    "    # Split 'data' column into 'date' and 'value'\n",
    "    df[['date', 'value']] = pd.DataFrame(df['data'].tolist(), index=df.index)\n",
    "    \n",
    "    # Remove the 'data' column\n",
    "    df = df.drop(columns=['data'])\n",
    "    \n",
    "    # Convert 'date' to datetime, coercing errors to NaT\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    # Convert 'value' to a numeric type, coercing errors to NaN\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    \n",
    "    # Sort by 'date' to ensure chronological order\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Calculate log of 'value' and the difference in log_price\n",
    "    df['log_price'] = np.log(df['value'])\n",
    "    df['price_change'] = df['log_price'].diff()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to perform AutoARIMA forecasting\n",
    "def forecast_prices(df_filtered):\n",
    "    with warnings.catch_warnings():\n",
    "        # Ignore specific warnings\n",
    "        warnings.simplefilter(\"ignore\", ValueWarning)\n",
    "        warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "        # Define the model\n",
    "        model = SARIMAX(df_filtered['log_price'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "        \n",
    "        # Fit the model\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Generate future dates with 'ME' instead of deprecated 'M'\n",
    "        future_dates = pd.date_range(df_filtered['date'].max() + MonthEnd(1), periods=13, freq='ME')\n",
    "        \n",
    "        # Forecast future log prices\n",
    "        forecast_log_prices = results.forecast(steps=13)\n",
    "        \n",
    "        # Convert log prices back to regular prices\n",
    "        forecast_prices = np.exp(forecast_log_prices)\n",
    "        \n",
    "        # Create a DataFrame for the forecasted prices\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'date': future_dates,\n",
    "            'forecast_price': forecast_prices\n",
    "        })\n",
    "        \n",
    "        return forecast_df\n",
    "\n",
    "# Visualization function\n",
    "def plot_forecast(df, forecast_df):\n",
    "    \"\"\"\n",
    "    Plots the historical oil prices along with the forecasted prices.\n",
    "\n",
    "    Parameters:\n",
    "    - df: A pandas DataFrame containing the historical data with columns 'date' and 'value'.\n",
    "    - forecast_df: A pandas DataFrame containing the forecasted data with columns 'date' and 'forecast_price'.\n",
    "\n",
    "    Returns:\n",
    "    - An Altair chart object that visualizes the historical and forecasted oil prices.\n",
    "    \"\"\"\n",
    "    # Base chart for historical data\n",
    "    base = alt.Chart(df).encode(\n",
    "        x=alt.X('date:T', title='Date'),\n",
    "        y=alt.Y('value:Q', title='Price')\n",
    "    ).properties(\n",
    "        width=700,\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    # Line chart for historical data\n",
    "    line = base.mark_line(color='blue', size=2, opacity=0.7).properties(\n",
    "        title=\"Historical and Forecasted Oil Prices\"\n",
    "    )\n",
    "\n",
    "    # Points for historical data\n",
    "    points = base.mark_point(color='red', size=50, opacity=0.5)\n",
    "\n",
    "    # Line chart for forecasted data\n",
    "    forecast_chart = alt.Chart(forecast_df).mark_line(color='green', size=2, opacity=0.7).encode(\n",
    "        x='date:T',\n",
    "        y=alt.Y('forecast_price:Q', title='Forecast Price')\n",
    "    )\n",
    "\n",
    "    # Combine the charts\n",
    "    chart = line + points + forecast_chart\n",
    "\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1967d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_gas_price_data('data/raw/PET/PET.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec131a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = prepare_data(df)\n",
    "df_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6332a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = forecast_prices(df_prepared)\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca84236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(df, forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'models/oil_price_forecast_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
