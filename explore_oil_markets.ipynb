{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ed01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       series_id  \\\n",
      "0  PET.EMM_EPMPR_PTE_Y35NY_DPG.W   \n",
      "1  PET.EMM_EPMPR_PTE_Y44HO_DPG.W   \n",
      "2  PET.EMM_EPMMR_PTE_R5XCA_DPG.W   \n",
      "3  PET.EMM_EPMMR_PTE_Y05LA_DPG.W   \n",
      "4  PET.EMM_EPMMR_PTE_Y05SF_DPG.W   \n",
      "\n",
      "                                                name               units  f  \\\n",
      "0  New York Harbor Premium Reformulated Retail Ga...  Dollars per Gallon  W   \n",
      "1  Houston, TX Premium Reformulated Retail Gasoli...  Dollars per Gallon  W   \n",
      "2  West Coast (PADD 5) Except California Midgrade...  Dollars per Gallon  W   \n",
      "3  Los Angeles, CA Midgrade Reformulated Retail G...  Dollars per Gallon  W   \n",
      "4  San Francisco, CA Midgrade Reformulated Retail...  Dollars per Gallon  W   \n",
      "\n",
      "  unitsshort                                        description copyright  \\\n",
      "0      $/gal  New York Harbor Premium Reformulated Retail Ga...      None   \n",
      "1      $/gal  Houston, TX Premium Reformulated Retail Gasoli...      None   \n",
      "2      $/gal  West Coast (PADD 5) Except California Midgrade...      None   \n",
      "3      $/gal  Los Angeles, CA Midgrade Reformulated Retail G...      None   \n",
      "4      $/gal  San Francisco, CA Midgrade Reformulated Retail...      None   \n",
      "\n",
      "                                        source iso3166  \\\n",
      "0  EIA, U.S. Energy Information Administration  USA-NY   \n",
      "1  EIA, U.S. Energy Information Administration  USA-TX   \n",
      "2  EIA, U.S. Energy Information Administration     NaN   \n",
      "3  EIA, U.S. Energy Information Administration  USA-CA   \n",
      "4  EIA, U.S. Energy Information Administration  USA-CA   \n",
      "\n",
      "                                   geography     start       end  \\\n",
      "0                                     USA-NY  20000605  20240617   \n",
      "1                                     USA-TX  20000605  20240617   \n",
      "2  USA-AK+USA-AZ+USA-HI+USA-NV+USA-OR+USA-WA  19980518  20240617   \n",
      "3                                     USA-CA  20000605  20240617   \n",
      "4                                     USA-CA  20000605  20240617   \n",
      "\n",
      "                last_updated  \\\n",
      "0  2024-06-17T22:10:18-04:00   \n",
      "1  2024-06-17T22:10:18-04:00   \n",
      "2  2024-06-17T22:10:18-04:00   \n",
      "3  2024-06-17T22:10:18-04:00   \n",
      "4  2024-06-17T22:10:18-04:00   \n",
      "\n",
      "                                                data geography2 category_id  \\\n",
      "0  [[20240617, 4.306], [20240610, 4.328], [202406...        NaN         NaN   \n",
      "1  [[20240617, 3.817], [20240610, 3.838], [202406...        NaN         NaN   \n",
      "2  [[20240617, 4.137], [20240610, 4.306], [202406...        NaN         NaN   \n",
      "3  [[20240617, 4.865], [20240610, 4.913], [202406...        NaN         NaN   \n",
      "4  [[20240617, 5.002], [20240610, 5.106], [202406...        NaN         NaN   \n",
      "\n",
      "  parent_category_id notes childseries  \n",
      "0                NaN   NaN         NaN  \n",
      "1                NaN   NaN         NaN  \n",
      "2                NaN   NaN         NaN  \n",
      "3                NaN   NaN         NaN  \n",
      "4                NaN   NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load the data from the text file\n",
    "data = pd.read_csv('data/raw/PET/PET.txt', sep='\\t', header=None, names=['json_str'])\n",
    "\n",
    "# Function to parse JSON strings\n",
    "def parse_json_str(json_str):\n",
    "    return json.loads(json_str)\n",
    "\n",
    "# Apply the function to parse the JSON strings\n",
    "parsed_data = data['json_str'].apply(parse_json_str)\n",
    "\n",
    "# Create a DataFrame from the parsed JSON data\n",
    "df = pd.json_normalize(parsed_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['series_id', 'name', 'units', 'f', 'unitsshort', 'description',\n",
       "       'copyright', 'source', 'iso3166', 'geography', 'start', 'end',\n",
       "       'last_updated', 'data', 'geography2', 'category_id',\n",
       "       'parent_category_id', 'notes', 'childseries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9482765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'data' column to separate rows for each date-value pair\n",
    "df = df.explode('data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select distinct series_id, name, units\n",
    "df_series = df[['series_id', 'name', 'units']].drop_duplicates()\n",
    "df_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a count of the number of records by units \n",
    "df_series['units'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df to only include name containing 'Louisiana' and units in Dollars per Gallon\n",
    "df_louisiana = df[df['name'].str.contains('Louisiana Total') & df['units'].str.contains('Dollars per Gallon')]\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17028f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'data' is NaN or not a list\n",
    "df_louisiana = df_louisiana.dropna(subset=['data'])\n",
    "df_louisiana = df_louisiana[df_louisiana['data'].apply(lambda x: isinstance(x, list) and len(x) == 2)]\n",
    "df_louisiana.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba622fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'data' column into 'date' and 'value'\n",
    "df_louisiana[['date', 'value']] = pd.DataFrame(df_louisiana['data'].tolist(), index=df_louisiana.index)\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5718761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime, coercing errors to NaT\n",
    "df_louisiana['date'] = pd.to_datetime(df_louisiana['date'], format='%Y%m%d', errors='coerce')\n",
    "# Convert 'value' to a numeric type, coercing errors to NaN\n",
    "df_louisiana['value'] = pd.to_numeric(df_louisiana['value'], errors='coerce')\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_louisiana.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns and preprocess the data\n",
    "df_louisiana['Date'] = pd.to_datetime(df_louisiana['date'])\n",
    "df_louisiana['Price'] = df_louisiana['value']\n",
    "#df_louisiana = df_louisiana[['Date', 'Price']].sort_values(by='Date').reset_index(drop=True)\n",
    "df_louisiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13752fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "def load_gas_price_data():\n",
    "    df = pd.read_csv('data\\processed\\louisiana_tot_gasoline_wholesale_monthly.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Convert 'date' to datetime, coercing errors\n",
    "    df = df[['date', 'value']].dropna()  # Keep only necessary columns and drop NA values\n",
    "    return df\n",
    "\n",
    "# Prepare data for long format and additional transformations\n",
    "def prepare_data(df):\n",
    "    df = df.sort_values('date')\n",
    "    df['log_price'] = np.log(df['value'])\n",
    "    df['price_change'] = df['log_price'].diff()\n",
    "    return df\n",
    "\n",
    "# Function to perform AutoARIMA forecasting\n",
    "def forecast_prices(df, cutoff_date):\n",
    "    # Filter the DataFrame based on the cutoff date\n",
    "    df_filtered = df[df['date'] < pd.to_datetime(cutoff_date)]\n",
    "    \n",
    "    # Convert prices to log prices to stabilize variance\n",
    "    df_filtered['log_price'] = np.log(df_filtered['value'])\n",
    "    \n",
    "    # Define the model\n",
    "    model = SARIMAX(df_filtered['log_price'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    \n",
    "    # Fit the model\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Generate future dates\n",
    "    future_dates = pd.date_range(df_filtered['date'].max() + MonthEnd(1), periods=13, freq='M')\n",
    "    \n",
    "    # Forecast future log prices\n",
    "    forecast_log_prices = results.forecast(steps=13)\n",
    "    \n",
    "    # Convert log prices back to regular prices\n",
    "    forecast_prices = np.exp(forecast_log_prices)\n",
    "    \n",
    "    # Create a DataFrame for the forecasted prices\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'date': future_dates,\n",
    "        'forecast_price': forecast_prices\n",
    "    })\n",
    "    \n",
    "    return forecast_df\n",
    "\n",
    "# Visualization function\n",
    "def plot_forecast(df, forecast_df):\n",
    "    base = alt.Chart(df).encode(\n",
    "        x='date:T',\n",
    "        y='value:Q'\n",
    "    ).properties(\n",
    "        width=700,\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    line = base.mark_line(color='blue', size=3)\n",
    "    points = base.mark_point(color='red')\n",
    "\n",
    "    forecast_chart = alt.Chart(forecast_df).mark_line(color='green').encode(\n",
    "        x='date:T',\n",
    "        y='forecast_price:Q'\n",
    "    )\n",
    "\n",
    "    return line + points + forecast_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1967d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_gas_price_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec131a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = prepare_data(df)\n",
    "df_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6332a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = forecast_prices(df, '2021-01-01')\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca84236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(df, forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'models/oil_price_forecast_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
